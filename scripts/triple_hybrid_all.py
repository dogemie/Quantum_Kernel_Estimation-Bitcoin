import numpy as np
import pandas as pd
import os
import joblib
from datetime import datetime
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

# [ì„¤ì •] í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë° ë°ì´í„° ê²½ë¡œ
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, ".."))
DATA_DIR = os.path.join(PROJECT_ROOT, "data")

def get_latest_folder(run_dir, prefix):
    """íŠ¹ì • ì ‘ë‘ì‚¬ë¡œ ì‹œì‘í•˜ëŠ” í´ë” ì¤‘ ê°€ì¥ ìµœê·¼ í´ë” ë°˜í™˜"""
    folders = [f for f in os.listdir(run_dir) if f.startswith(prefix) and os.path.isdir(os.path.join(run_dir, f))]
    return os.path.join(run_dir, sorted(folders)[-1]) if folders else None

def has_hybrid_folder(run_dir):
    """ì´ë¯¸ í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    folders = [f for f in os.listdir(run_dir) if f.startswith("hybrid_comparison_")]
    return len(folders) > 0

def run_hybrid_analysis(run_folder_name):
    run_dir = os.path.join(DATA_DIR, run_folder_name)
    seed = int(run_folder_name.replace("run_", ""))
    
    # 1. ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€ ì²´í¬
    if has_hybrid_folder(run_dir):
        print(f"â© [Skip] {run_folder_name}: í•˜ì´ë¸Œë¦¬ë“œ ê²°ê³¼ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        return

    print(f"ğŸš€ [Process] {run_folder_name}: í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤.")

    # 2. ê²½ë¡œ ì„¤ì • ë° ëª¨ë¸ ë¡œë“œ
    csvm_folder = get_latest_folder(run_dir, "classical_svm_")
    qsvm_folder = get_latest_folder(run_dir, "quantum_kernel_")
    
    if not csvm_folder or not qsvm_folder:
        print(f"âš ï¸ [Error] {run_folder_name}: ëª¨ë¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return

    save_dir = os.path.join(run_dir, f"hybrid_comparison_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
    os.makedirs(save_dir, exist_ok=True)

    # ëª¨ë¸ ë° ë°ì´í„° ë¡œë“œ
    csvm = joblib.load(os.path.join(csvm_folder, "classical_svm_model.pkl"))
    qsvm = joblib.load(os.path.join(qsvm_folder, "qsvm_model.pkl"))
    X = np.load(os.path.join(run_dir, "X_quantum.npy"))
    y = np.load(os.path.join(run_dir, "y_label.npy")).astype(int)
    gram_train = np.load(os.path.join(qsvm_folder, "gram_train.npy"))
    gram_test = np.load(os.path.join(qsvm_folder, "gram_test.npy"))
    
    # ë°ì´í„° ë¶„í•  (ê¸°ì¡´ ì‹¤í—˜ê³¼ ë™ì¼í•œ seed ì‚¬ìš©)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed, stratify=y)

    # 3. í™•ë¥ ê°’ ì¶”ì¶œ
    prob_c = csvm.predict_proba(X_test)
    prob_q = qsvm.predict_proba(gram_test)
    prob_c_train = csvm.predict_proba(X_train)
    prob_q_train = qsvm.predict_proba(gram_train)

    results = {}
    target_names = ['Normal', 'Dip', 'Flash', 'Vol']

    # --- [ê¸°ë²• 1: ì˜ì‚¬ê²°ì • ìœµí•© (Decision Fusion)] ---
    # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ì— ë”°ë¼ í•©ì‚°
    weights = np.array([0.6005, 0.6755, 0.2815, 0.4825]) # Dip(1)ì— ì–‘ì ê°€ì¤‘ì¹˜ ì§‘ì¤‘
    prob_fusion = (prob_q * weights) + (prob_c * (1 - weights))
    results['Hybrid_Fusion'] = np.argmax(prob_fusion, axis=1)

    # --- [ê¸°ë²• 2: ê³„ì¸µì  ë¶„ë¥˜ (Cascading)] ---
    # CSVM ê²°ê³¼ê°€ ëª¨í˜¸í•  ë•Œë§Œ QSVMì—ê²Œ ìµœì¢… íŒë‹¨ì„ ë§¡ê¹€
    threshold = 0.6
    y_cascading = []
    for i in range(len(prob_c)):
        if np.max(prob_c[i]) < threshold:
            y_cascading.append(np.argmax(prob_q[i]))
        else:
            y_cascading.append(np.argmax(prob_c[i]))
    results['Hybrid_Cascading'] = np.array(y_cascading)

    # --- [ê¸°ë²• 3: ë©”íƒ€ í•™ìŠµ (Stacked Generalization)] ---
    # CSVMê³¼ QSVMì˜ ì˜ˆì¸¡ê°’ì„ ìƒˆë¡œìš´ íŠ¹ì§•ìœ¼ë¡œ ì‚¼ì•„ ìµœì¢… ê²°ì •
    X_meta_train = np.hstack([prob_c_train, prob_q_train])
    X_meta_test = np.hstack([prob_c, prob_q])
    meta_model = LogisticRegression().fit(X_meta_train, y_train) # ì¸ë±ìŠ¤ ì˜¤ë¥˜ ìˆ˜ì • ì™„ë£Œ
    results['Hybrid_Stacking'] = meta_model.predict(X_meta_test)

    # ë² ì´ìŠ¤ë¼ì¸ ê¸°ë¡
    results['Baseline_CSVM'] = np.argmax(prob_c, axis=1)
    results['Baseline_QSVM'] = np.argmax(prob_q, axis=1)

    # 4. ê²°ê³¼ ì €ì¥
    comparison_data = []
    for name, y_pred in results.items():
        report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True, zero_division=0)
        pd.DataFrame(report).transpose().to_csv(os.path.join(save_dir, f"metrics_{name}.csv"))
        
        comparison_data.append({
            "Method": name,
            "Accuracy": report['accuracy'],
            "Macro_F1": report['macro avg']['f1-score'],
            "Dip_F1": report['Dip']['f1-score'],
            "Vol_F1": report['Vol']['f1-score']
        })

    pd.DataFrame(comparison_data).to_csv(os.path.join(save_dir, "hybrid_total_comparison.csv"), index=False)
    print(f"âœ… [Done] {run_folder_name}: ë¶„ì„ ì™„ë£Œ ë° ì €ì¥ ({save_dir})")

def main():
    if not os.path.exists(DATA_DIR):
        print(f"âŒ ë°ì´í„° í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤: {DATA_DIR}")
        return

    run_folders = [f for f in os.listdir(DATA_DIR) if f.startswith("run_") and os.path.isdir(os.path.join(DATA_DIR, f))]
    print(f"ğŸ” ì´ {len(run_folders)}ê°œì˜ ì‹¤í—˜ í´ë”ë¥¼ ê²€ì‚¬í•©ë‹ˆë‹¤.")

    for run_folder in sorted(run_folders):
        try:
            run_hybrid_analysis(run_folder)
        except Exception as e:
            print(f"âŒ {run_folder} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

if __name__ == "__main__":
    main()